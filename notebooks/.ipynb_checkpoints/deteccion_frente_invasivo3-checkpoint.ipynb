{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59bac8-56b7-48d1-8978-d064041b17b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d386beaf-77ab-4c53-9125-1517593c6097",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1933874046.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    AÑADO ROCS:\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "todo completo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1853a83b-110f-46db-9216-808ceb574215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "[INFO] Found 2003 patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Confocal\\AppData\\Local\\Temp\\ipykernel_15936\\2406936959.py:189: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler=GradScaler()\n",
      "Train 1:   0%|                                                                                | 0/1602 [00:00<?, ?it/s]C:\\Users\\Confocal\\AppData\\Local\\Temp\\ipykernel_15936\\2406936959.py:197: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Train 1: 100%|█████████████████████████████████████████████████████████████████████| 1602/1602 [23:09<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep1] Train Loss: 0.7383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Val 1:   0%|                                                                                  | 0/401 [00:00<?, ?it/s]C:\\Users\\Confocal\\AppData\\Local\\Temp\\ipykernel_15936\\2406936959.py:211: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      " Val 1: 100%|████████████████████████████████████████████████████████████████████████| 401/401 [01:58<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep1] Val Loss:   0.6412\n",
      "[INFO] Saved trained model to results\\20250529_171815\\models\\unet_20250529_171815.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Confocal\\AppData\\Local\\Temp\\ipykernel_15936\\2406936959.py:370: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Results are in results\\20250529_171815\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.ndimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# GLOBAL CONFIGURATION\n",
    "# --------------------------------------------------------------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RESULTS_ROOT = os.path.join(\"results\", timestamp)\n",
    "os.makedirs(RESULTS_ROOT, exist_ok=True)\n",
    "\n",
    "MODEL_DIR    = os.path.join(RESULTS_ROOT, \"models\")\n",
    "OVERLAYS_DIR = os.path.join(RESULTS_ROOT, \"overlays\")\n",
    "METRICS_DIR  = os.path.join(RESULTS_ROOT, \"metrics_plots\")\n",
    "for d in (MODEL_DIR, OVERLAYS_DIR, METRICS_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# COLORS & CLASSES\n",
    "# --------------------------------------------------------------------------------\n",
    "my_colors = {\n",
    "    0: (1.0,0.65,0.0,1.0),\n",
    "    1: (1.0,0.0,0.0,1.0),\n",
    "    2: (0.0,1.0,0.0,1.0),\n",
    "}\n",
    "class_names = {\n",
    "    0: \"Background\",\n",
    "    1: \"Front of Invasion\",\n",
    "    2: \"Stroma\",\n",
    "}\n",
    "\n",
    "cmap_vals = np.zeros((256,4))\n",
    "for k,v in my_colors.items():\n",
    "    cmap_vals[k] = v\n",
    "unet_cmap = mcolors.ListedColormap(cmap_vals)\n",
    "\n",
    "viz_colors = {0:my_colors[0],1:my_colors[1],2:my_colors[2],4:(0,0,0,0)}\n",
    "custom_viz_cmap = mcolors.ListedColormap([viz_colors[i] for i in sorted(viz_colors)])\n",
    "\n",
    "def prepare_mask_for_viz(m):\n",
    "    m2 = m.copy()\n",
    "    m2[m2==-1]=4\n",
    "    return m2\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# U-Net + SE Blocks\n",
    "# --------------------------------------------------------------------------------\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self,in_ch,reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(in_ch,in_ch//reduction)\n",
    "        self.fc2=nn.Linear(in_ch//reduction,in_ch)\n",
    "    def forward(self,x):\n",
    "        b,c,_,_=x.size()\n",
    "        y=F.adaptive_avg_pool2d(x,1).view(b,c)\n",
    "        y=F.relu(self.fc1(y),inplace=True)\n",
    "        y=torch.sigmoid(self.fc2(y)).view(b,c,1,1)\n",
    "        return x*y\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch,kernel=3,dilation=1):\n",
    "        super().__init__()\n",
    "        pad=((kernel-1)*dilation)//2\n",
    "        self.block=nn.Sequential(\n",
    "            nn.Conv2d(in_ch,out_ch,kernel,padding=pad,dilation=dilation),\n",
    "            nn.BatchNorm2d(out_ch),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch,out_ch,kernel,padding=pad,dilation=dilation),\n",
    "            nn.BatchNorm2d(out_ch),nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.se=SEBlock(out_ch)\n",
    "    def forward(self,x):\n",
    "        x=self.block(x)\n",
    "        return self.se(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,in_ch=2,base=32,classes=3):\n",
    "        super().__init__()\n",
    "        c1,c2,c3,c4,c5=base,base*2,base*4,base*8,base*16\n",
    "        self.d1=DoubleConv(in_ch,c1); self.p1=nn.MaxPool2d(2)\n",
    "        self.d2=DoubleConv(c1,c2); self.p2=nn.MaxPool2d(2)\n",
    "        self.d3=DoubleConv(c2,c3,dilation=2); self.p3=nn.MaxPool2d(2)\n",
    "        self.d4=DoubleConv(c3,c4,dilation=4); self.p4=nn.MaxPool2d(2)\n",
    "        self.b=DoubleConv(c4,c5,dilation=4)\n",
    "        self.u4=nn.ConvTranspose2d(c5,c4,2,2); self.c4=DoubleConv(c4*2,c4,dilation=2)\n",
    "        self.u3=nn.ConvTranspose2d(c4,c3,2,2); self.c3=DoubleConv(c3*2,c3)\n",
    "        self.u2=nn.ConvTranspose2d(c3,c2,2,2); self.c2=DoubleConv(c2*2,c2)\n",
    "        self.u1=nn.ConvTranspose2d(c2,c1,2,2); self.c1=DoubleConv(c1*2,c1)\n",
    "        self.final=nn.Conv2d(c1,classes,1)\n",
    "    def forward(self,x):\n",
    "        c1=self.d1(x); p1=self.p1(c1)\n",
    "        c2=self.d2(p1); p2=self.p2(c2)\n",
    "        c3=self.d3(p2); p3=self.p3(c3)\n",
    "        c4=self.d4(p3); p4=self.p4(c4)\n",
    "        bn=self.b(p4)\n",
    "        u4=self.u4(bn); m4=torch.cat([u4,c4],1); c5=self.c4(m4)\n",
    "        u3=self.u3(c5); m3=torch.cat([u3,c3],1); c6=self.c3(m3)\n",
    "        u2=self.u2(c6); m2=torch.cat([u2,c2],1); c7=self.c2(m2)\n",
    "        u1=self.u1(c7); m1=torch.cat([u1,c1],1); c8=self.c1(m1)\n",
    "        return self.final(c8)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# DATASET\n",
    "# --------------------------------------------------------------------------------\n",
    "def get_valid_pairs(d):\n",
    "    files=os.listdir(d)\n",
    "    pairs=[]\n",
    "    for f in files:\n",
    "        if not (f.startswith(\"patch_\") and f.endswith(\".png\")): continue\n",
    "        num=f.split(\"_\")[1].split(\".\")[0]\n",
    "        rgb,hema,eos,msk=[os.path.join(d,p) for p in (\n",
    "            f,f.replace(\"patch_\",\"hematoxilin_\"),\n",
    "            f.replace(\"patch_\",\"eosin_\"),f.replace(\"patch_\",\"mask_\")\n",
    "        )]\n",
    "        if not all(os.path.exists(p) for p in (rgb,hema,eos,msk)): continue\n",
    "        m=cv2.imread(msk,0)\n",
    "        m=np.where(np.isin(m,[0,1,2]),m,-1)\n",
    "        if {1,2}&set(np.unique(m)): pairs.append((rgb,hema,eos,msk))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, pairs, augment=False):\n",
    "        self.pairs = pairs\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_f, hema_f, eosin_f, mask_f = self.pairs[idx]\n",
    "        h = cv2.imread(hema_f, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255.0\n",
    "        e = cv2.imread(eosin_f, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255.0\n",
    "        m = cv2.imread(mask_f, cv2.IMREAD_GRAYSCALE)\n",
    "        if h.shape != m.shape:\n",
    "            m = cv2.resize(m, (h.shape[1], h.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        m = np.where(np.isin(m, [0, 1, 2]), m, -1)\n",
    "\n",
    "        ch = np.stack([h, e], axis=0)\n",
    "\n",
    "        if self.augment:\n",
    "            if random.random() > 0.5:\n",
    "                ch, m = ch[:, :, ::-1], m[:, ::-1]\n",
    "            if random.random() > 0.5:\n",
    "                ch, m = ch[:, ::-1, :], m[::-1, :]\n",
    "            k = random.randint(0, 3)\n",
    "            if k:\n",
    "                ch = np.rot90(ch, k, axes=(1, 2))\n",
    "                m = np.rot90(m, k)\n",
    "            delta = np.float32(random.uniform(-0.1, 0.1))\n",
    "            ch = np.clip(ch + delta, 0, 1)\n",
    "            noise = np.random.normal(0, 0.02, size=ch.shape).astype(np.float32)\n",
    "            ch = np.clip(ch + noise, 0, 1)\n",
    "\n",
    "        # **Aquí nos aseguramos de que no haya strides negativas**\n",
    "        ch = np.ascontiguousarray(ch, dtype=np.float32)\n",
    "        m  = np.ascontiguousarray(m)\n",
    "\n",
    "        return torch.from_numpy(ch), torch.from_numpy(m).long()\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# TRAINING\n",
    "# --------------------------------------------------------------------------------\n",
    "def train_model(model,train_ds,val_ds,epochs=5,lr=1e-4,bs=1,accum=4):\n",
    "    opt=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    crit=nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    scaler=GradScaler()\n",
    "    tr_dl=DataLoader(train_ds,batch_size=bs,shuffle=True,pin_memory=True)\n",
    "    val_dl=DataLoader(val_ds,batch_size=bs,shuffle=False,pin_memory=True)\n",
    "    for ep in range(1,epochs+1):\n",
    "        model.train(); opt.zero_grad(set_to_none=True)\n",
    "        tloss=0\n",
    "        for i,(x,y) in enumerate(tqdm(tr_dl,desc=f\"Train {ep}\")):\n",
    "            x,y=x.to(device),y.to(device)\n",
    "            with autocast():\n",
    "                out=model(x)\n",
    "                if out.shape[2:]!=y.shape[1:]:\n",
    "                    y=F.interpolate(y.unsqueeze(1).float(),size=out.shape[2:],mode=\"nearest\")\\\n",
    "                       .squeeze(1).long()\n",
    "                loss=crit(out,y)/accum\n",
    "            scaler.scale(loss).backward(); tloss+=loss.item()*accum\n",
    "            if (i+1)%accum==0 or (i+1)==len(tr_dl):\n",
    "                scaler.step(opt); scaler.update(); opt.zero_grad(set_to_none=True)\n",
    "        print(f\"[Ep{ep}] Train Loss: {tloss/len(tr_dl):.4f}\")\n",
    "        model.eval(); vloss=0\n",
    "        with torch.no_grad():\n",
    "            for x,y in tqdm(val_dl,desc=f\" Val {ep}\"):\n",
    "                x,y=x.to(device),y.to(device)\n",
    "                with autocast():\n",
    "                    out=model(x)\n",
    "                    if out.shape[2:]!=y.shape[1:]:\n",
    "                        y=F.interpolate(y.unsqueeze(1).float(),size=out.shape[2:],mode=\"nearest\")\\\n",
    "                           .squeeze(1).long()\n",
    "                    vloss+=crit(out,y).item()\n",
    "        print(f\"[Ep{ep}] Val Loss:   {vloss/len(val_dl):.4f}\")\n",
    "    return model\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# PREDICTION & OVERLAYS\n",
    "# --------------------------------------------------------------------------------\n",
    "apply_ma=lambda p,ks=3:scipy.ndimage.generic_filter(p,lambda v:np.bincount(v.astype(int)).argmax(),size=ks)\n",
    "\n",
    "def save_overlay(rgb, pred, idx, truth, sub):\n",
    "    sd = os.path.join(OVERLAYS_DIR, sub)\n",
    "    os.makedirs(sd, exist_ok=True)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    ax1, ax2, ax3 = axes\n",
    "\n",
    "    ax1.imshow(rgb)\n",
    "    ax1.set_title(\"Original\")\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    ax2.imshow(pred, cmap=unet_cmap, norm=mcolors.NoNorm())\n",
    "    ax2.set_title(\"Predicted\")\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    m2 = prepare_mask_for_viz(truth)\n",
    "    ax3.imshow(m2, cmap=custom_viz_cmap, norm=mcolors.NoNorm())\n",
    "    ax3.set_title(\"GroundTruth\")\n",
    "    ax3.axis(\"off\")\n",
    "\n",
    "    # Preparamos la leyenda\n",
    "    handles = [mpatches.Patch(color=my_colors[c], label=class_names[c])\n",
    "               for c in sorted(class_names)]\n",
    "    labels  = [class_names[c] for c in sorted(class_names)]\n",
    "\n",
    "    # Añadimos la leyenda justo a la derecha de los ejes, centrada verticalmente\n",
    "    fig.legend(\n",
    "        handles, labels,\n",
    "        loc=\"center right\",\n",
    "        bbox_to_anchor=(1.05, 0.8), \n",
    "        ncol=1,\n",
    "        frameon=False\n",
    "    )\n",
    "\n",
    "    # Ajustamos márgenes para dejar un poquito de hueco a la derecha\n",
    "    fig.subplots_adjust(\n",
    "        left=0.05,\n",
    "        right=0.95,   # ahora los ejes ocupan hasta el 95% del ancho\n",
    "        top=0.95,\n",
    "        bottom=0.05,\n",
    "        wspace=0.2\n",
    "    )\n",
    "\n",
    "    fig.savefig(\n",
    "        os.path.join(sd, f\"overlay_{idx}.svg\"),\n",
    "        format=\"svg\", dpi=150, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def predict_and_collect(model,ds,pairs,ma_kernel=5):\n",
    "    trs=[];prs=[];probs=[]\n",
    "    for idx,((x,y),(rgb,_,_,_)) in enumerate(zip(ds,pairs)):\n",
    "        img=cv2.cvtColor(cv2.imread(rgb),cv2.COLOR_BGR2RGB)\n",
    "        xb=x.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits=model(xb)\n",
    "            P=F.softmax(logits,dim=1).cpu().numpy()[0]\n",
    "            pr=np.argmax(P,axis=0).astype(np.uint8)\n",
    "        sm=apply_ma(pr,ks=ma_kernel)\n",
    "        save_overlay(img,sm,idx,y.numpy(),f\"ma_{ma_kernel}\")\n",
    "        trs.append(y.numpy().flatten()); prs.append(sm.flatten())\n",
    "        h,w=P.shape[1:]\n",
    "        probs.append(P.transpose(1,2,0).reshape(-1,P.shape[0]))\n",
    "    return np.concatenate(trs),np.concatenate(prs),np.vstack(probs)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# METRICS & PLOTS\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "def save_conf(cm, name):\n",
    "    df = pd.DataFrame(cm, index=class_names.values(), columns=class_names.values())\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(df, cmap=\"viridis\", interpolation=\"nearest\")\n",
    "    ax.set_title(name)\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    ticks = np.arange(len(df))\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(df.columns, rotation=0)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels(df.index)\n",
    "    for i, j in np.ndindex(df.shape):\n",
    "        ax.text(j, i, int(df.iat[i, j]), ha=\"center\", va=\"center\", color=\"white\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "\n",
    "    # Ajuste de márgenes para que no se corten las etiquetas\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(left=0.2)\n",
    "\n",
    "    fig.savefig(\n",
    "        os.path.join(METRICS_DIR, f\"{name.replace(' ', '_')}.svg\"),\n",
    "        format=\"svg\",\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def save_norm_conf(cm, name):\n",
    "    cmn = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "    df = pd.DataFrame(cmn, index=class_names.values(), columns=class_names.values())\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(df, cmap=\"Blues\", vmin=0, vmax=1)\n",
    "    ax.set_title(name)\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    ticks = np.arange(len(df))\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(df.columns, rotation=0)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels(df.index)\n",
    "    for i, j in np.ndindex(df.shape):\n",
    "        ax.text(j, i, f\"{df.iat[i, j]:.2f}\", ha=\"center\", va=\"center\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "\n",
    "    # Ajuste de márgenes para que no se corten las etiquetas\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(left=0.2)\n",
    "\n",
    "    fig.savefig(\n",
    "        os.path.join(METRICS_DIR, f\"{name.replace(' ', '_')}.svg\"),\n",
    "        format=\"svg\",\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def save_iou_dice(cm):\n",
    "    tp=np.diag(cm); fp=cm.sum(axis=0)-tp; fn=cm.sum(axis=1)-tp\n",
    "    iou=tp/(tp+fp+fn); dice=2*tp/(2*tp+fp+fn)\n",
    "    classes=list(class_names.values()); x=np.arange(len(classes)); w=0.35\n",
    "    fig,ax=plt.subplots(figsize=(7,4))\n",
    "    ax.bar(x-w/2,iou,w,label=\"IoU\"); ax.bar(x+w/2,dice,w,label=\"Dice\")\n",
    "    ax.set_xticks(x); ax.set_xticklabels(classes); ax.set_ylim(0,1)\n",
    "    ax.set_ylabel(\"Score\"); ax.set_title(\"IoU vs Dice per Class\"); ax.legend()\n",
    "    fig.savefig(os.path.join(METRICS_DIR,\"IoU_vs_Dice.svg\"),format=\"svg\")\n",
    "    plt.close(fig)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def save_patch_iou(tr, pr, pairs):\n",
    "    \"\"\"\n",
    "    Calcula el IoU por parche para las clases 1 y 2,\n",
    "    filtrando denominadores cero para evitar nan/warnings,\n",
    "    y dibuja un boxplot solo con los valores válidos,\n",
    "    incluyendo una leyenda para el marcador de la media.\n",
    "    \"\"\"\n",
    "    ious = []  # aquí almacenaremos vectores [iou0, iou1, iou2]\n",
    "\n",
    "    for t_patch, p_patch in zip(\n",
    "        np.split(tr, len(pairs)),\n",
    "        np.split(pr, len(pairs))\n",
    "    ):\n",
    "        cm = confusion_matrix(t_patch, p_patch, labels=[0,1,2])\n",
    "        tp = np.diag(cm)\n",
    "        fp = cm.sum(axis=0) - tp\n",
    "        fn = cm.sum(axis=1) - tp\n",
    "        denom = tp + fp + fn\n",
    "\n",
    "        iou = np.zeros_like(tp, dtype=float)\n",
    "        valid = denom > 0\n",
    "        iou[valid] = tp[valid] / denom[valid]\n",
    "        ious.append(iou)\n",
    "\n",
    "    ious = np.vstack(ious)\n",
    "\n",
    "\n",
    "\n",
    "    # dibujamos el boxplot\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    bp = ax.boxplot(\n",
    "        [ious[:,1], ious[:,2]],\n",
    "        labels=[\"Front Of Invasion\",\"Stroma\"],\n",
    "        showmeans=True,\n",
    "        meanprops={\"marker\":\"D\", \"markeredgecolor\":\"black\", \"markerfacecolor\":\"white\"}\n",
    "    )\n",
    "    ax.set_ylabel(\"IoU\")\n",
    "    ax.set_title(\"Per-Patch IoU\")\n",
    "\n",
    "    # añadimos leyenda para el marcador de la media\n",
    "    mean_handle = Line2D(\n",
    "        [0], [0],\n",
    "        marker='D',\n",
    "        color='none',\n",
    "        markeredgecolor='black',\n",
    "        markerfacecolor='white',\n",
    "        markersize=8,\n",
    "        linestyle='None',\n",
    "        label='Mean'\n",
    "    )\n",
    "    ax.legend(handles=[mean_handle], loc='upper right')\n",
    "\n",
    "    # guardamos la figura\n",
    "    fig.savefig(\n",
    "        os.path.join(METRICS_DIR,\"Per_Patch_IoU.svg\"),\n",
    "        format=\"svg\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def save_metrics_per_class(cm):\n",
    "    \"\"\"\n",
    "    Plot per-class Precision, Recall, F1-Score y Accuracy como gráficos de barras agrupadas,\n",
    "    mostrando primero Accuracy, luego Precision, Recall y F1-Score.\n",
    "    \"\"\"\n",
    "    # Descomposición de la matriz de confusión\n",
    "    tp = np.diag(cm)\n",
    "    fp = cm.sum(axis=0) - tp\n",
    "    fn = cm.sum(axis=1) - tp\n",
    "    total_samples = cm.sum()\n",
    "\n",
    "    # Cálculo de Precision / Recall / F1 para cada clase\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        precision_pc = tp / (tp + fp)\n",
    "        recall_pc    = tp / (tp + fn)\n",
    "        f1_pc        = 2 * precision_pc * recall_pc / (precision_pc + recall_pc)\n",
    "        # Accuracy por clase: (TP + TN) / Total\n",
    "        tn = total_samples - (tp + fp + fn)\n",
    "        accuracy_pc  = (tp + tn) / total_samples\n",
    "    save_metrics_per_class(cm)\n",
    "\n",
    "    # Sustituir NaNs por ceros\n",
    "    precision_pc = np.nan_to_num(precision_pc)\n",
    "    recall_pc    = np.nan_to_num(recall_pc)\n",
    "    f1_pc        = np.nan_to_num(f1_pc)\n",
    "    accuracy_pc  = np.nan_to_num(accuracy_pc)\n",
    "\n",
    "    classes = list(class_names.values())\n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    # Orden de barras: Accuracy, Precision, Recall, F1 Score\n",
    "    ax.bar(x - 1.5*width, accuracy_pc,  width, label='Accuracy')\n",
    "    ax.bar(x - 0.5*width, precision_pc, width, label='Precision')\n",
    "    ax.bar(x + 0.5*width, recall_pc,    width, label='Recall')\n",
    "    ax.bar(x + 1.5*width, f1_pc,        width, label='F1 Score')\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(classes, rotation=0, ha='right')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Per-Class Segmentation Metrics')\n",
    "\n",
    "    # Leyenda a la derecha\n",
    "    legend = ax.legend(\n",
    "        loc='upper left',\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        borderaxespad=0,\n",
    "        frameon=True\n",
    "    )\n",
    "    legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "    # Anotar cada barra con su valor\n",
    "    for i in range(len(classes)):\n",
    "        ax.text(x[i] - 1.5*width, accuracy_pc[i]  + 0.02, f\"{accuracy_pc[i]:.2f}\",  ha='center')\n",
    "        ax.text(x[i] - 0.5*width, precision_pc[i] + 0.02, f\"{precision_pc[i]:.2f}\", ha='center')\n",
    "        ax.text(x[i] + 0.5*width, recall_pc[i]    + 0.02, f\"{recall_pc[i]:.2f}\",    ha='center')\n",
    "        ax.text(x[i] + 1.5*width, f1_pc[i]        + 0.02, f\"{f1_pc[i]:.2f}\",        ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\n",
    "        os.path.join(METRICS_DIR, \"Metrics_Per_Class.svg\"),\n",
    "        format=\"svg\", dpi=150, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_overall_metrics_from_cm(cm):\n",
    "    \"\"\"\n",
    "    Compute global Accuracy, macro‐Precision, macro‐Recall and macro‐F1 \n",
    "    from the confusion matrix, and save as a bar chart.\n",
    "    \"\"\"\n",
    "    tp = np.diag(cm)\n",
    "    fp = cm.sum(axis=0) - tp\n",
    "    fn = cm.sum(axis=1) - tp\n",
    "    total = cm.sum()\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = tp.sum() / total\n",
    "\n",
    "    # per‐class Precision / Recall / F1\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        precision_pc = tp / (tp + fp)\n",
    "        recall_pc    = tp / (tp + fn)\n",
    "        f1_pc        = 2 * precision_pc * recall_pc / (precision_pc + recall_pc)\n",
    "    precision_pc = np.nan_to_num(precision_pc)\n",
    "    recall_pc    = np.nan_to_num(recall_pc)\n",
    "    f1_pc        = np.nan_to_num(f1_pc)\n",
    "\n",
    "    # macro‐averages\n",
    "    precision = precision_pc.mean()\n",
    "    recall    = recall_pc.mean()\n",
    "    f1_score  = f1_pc.mean()\n",
    "\n",
    "    metrics = {\n",
    "        'Accuracy':   accuracy,\n",
    "        'Precision':  precision,\n",
    "        'Recall':     recall,\n",
    "        'F1-Score':   f1_score\n",
    "    }\n",
    "    names, values = zip(*metrics.items())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.bar(names, values)\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Overall Segmentation Metrics')\n",
    "    for i, v in enumerate(values):\n",
    "        ax.text(i, v + 0.02, f\"{v:.2f}\", ha='center')\n",
    "    fig.savefig(\n",
    "        os.path.join(METRICS_DIR, \"Overall_Metrics.svg\"),\n",
    "        format=\"svg\", dpi=150, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_area_scatter(tr,pr,pairs):\n",
    "    true_cnt=[]; pred_cnt=[]; idx=0\n",
    "    for _,_,_,msk in pairs:\n",
    "        gt=cv2.imread(msk,0).flatten()\n",
    "        true_cnt.append((gt==1).sum())\n",
    "        pred_cnt.append((pr[idx:idx+gt.size]==1).sum())\n",
    "        idx+=gt.size\n",
    "    fig,ax=plt.subplots(figsize=(5,5))\n",
    "    ax.scatter(true_cnt,pred_cnt,alpha=0.7)\n",
    "    m=max(max(true_cnt),max(pred_cnt))\n",
    "    ax.plot([0,m],[0,m],'k--')\n",
    "    ax.set_xlabel(\"True FOI Pixels\"); ax.set_ylabel(\"Pred FOI Pixels\"); ax.set_title(\"Area Scatter\")\n",
    "    fig.savefig(os.path.join(METRICS_DIR,\"Area_Scatter.svg\"),format=\"svg\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_roc(tr, prob, max_samples=200_000, seed=42):\n",
    "    \"\"\"\n",
    "    Guarda las curvas ROC/AUC por clase, muestreando como máximo `max_samples` píxeles.\n",
    "    Para n > max_samples utiliza random.sample sobre range(n) sin cargar todo en RAM.\n",
    "    \"\"\"\n",
    "    n = tr.shape[0]\n",
    "    if n > max_samples:\n",
    "        random.seed(seed)\n",
    "        # sample sin reemplazo directamente de range(n)\n",
    "        idx = random.sample(range(n), k=max_samples)\n",
    "        tr_sub   = tr[idx]\n",
    "        prob_sub = prob[idx]\n",
    "    else:\n",
    "        tr_sub, prob_sub = tr, prob\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    for cls in range(prob_sub.shape[1]):\n",
    "        yt = (tr_sub == cls).astype(int)\n",
    "        fpr, tpr, _ = roc_curve(yt, prob_sub[:, cls])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax.plot(fpr, tpr, label=f\"{class_names[cls]} (AUC={roc_auc:.2f})\")\n",
    "\n",
    "    ax.plot([0,1], [0,1], 'k--')\n",
    "    ax.set_xlabel(\"FPR\")\n",
    "    ax.set_ylabel(\"TPR\")\n",
    "    ax.set_title(\"ROC Curves\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    fig.savefig(\n",
    "        os.path.join(METRICS_DIR, \"ROC_Curves.svg\"),\n",
    "        format=\"svg\", dpi=150\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# MAIN\n",
    "# --------------------------------------------------------------------------------\n",
    "if __name__==\"__main__\":\n",
    "    patch_dir = r\"C:\\Temp\\patches_2048\\HC22B0006126_HEmascaras_tumor_oversampled_balanced\"\n",
    "    pairs = get_valid_pairs(patch_dir)\n",
    "    print(f\"[INFO] Found {len(pairs)} patches.\")\n",
    "\n",
    "    # split\n",
    "    strat=[]\n",
    "    for *_,m in pairs:\n",
    "        gt=cv2.imread(m,0); gt=np.where(np.isin(gt,[0,1,2]),gt,-1)\n",
    "        u,c=np.unique(gt,return_counts=True)\n",
    "        valid=[(u_,c_) for u_,c_ in zip(u,c) if u_ in [0,1,2]]\n",
    "        strat.append(max(valid,key=lambda x:x[1])[0] if valid else 0)\n",
    "    train_p, test_p = train_test_split(pairs, test_size=0.2, stratify=strat, random_state=42)\n",
    "    ds_tr = PatchDataset(train_p, augment=True)\n",
    "    ds_te = PatchDataset(test_p, augment=False)\n",
    "\n",
    "    # ----- OPTION A: Train from scratch -----\n",
    "    # Uncomment this block to train a new model\n",
    "\n",
    "    model = UNet(in_ch=2, base=64).to(device)\n",
    "    model = train_model(model, ds_tr, ds_te, epochs=1, lr=1e-4, bs=1, accum=4)\n",
    "    model_path = os.path.join(MODEL_DIR, f\"unet_{timestamp}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"[INFO] Saved trained model to {model_path}\")\n",
    "    trained = model\n",
    "\n",
    "    # ----- OPTION B: Load existing model -----\n",
    "    # Uncomment this block to load a previously trained model\n",
    "    \n",
    "    #\"\"\"\n",
    "    #model = UNet(in_ch=2, base=64).to(device)\n",
    "    #model_path = r\"\\\\imgserver.cnio.es\\IMAGES\\CONFOCAL\\IA\\CMU\\tfm_colab\\patrones_invasion\\notebooks\\results\\20250527_130513\\models\\unet_20250527_130513.pth\"\n",
    "    #state = torch.load(model_path, map_location=device)\n",
    "    #model.load_state_dict(state)\n",
    "    #model.eval()\n",
    "    #print(f\"[INFO] Loaded model from {model_path}\")\n",
    "    #trained = model\n",
    "    #\"\"\"\n",
    "\n",
    "    # ---- end train/load choice ----\n",
    "\n",
    "    # Predict & collect\n",
    "    all_t, all_p, all_prob = predict_and_collect(trained, ds_te, test_p, ma_kernel=5)\n",
    "\n",
    "    # Confusion matrix & metrics\n",
    "    cm = confusion_matrix(all_t, all_p, labels=[0,1,2])\n",
    "    save_conf(cm,\"Confusion Matrix\")\n",
    "    save_norm_conf(cm,\"Normalized Confusion Matrix\")\n",
    "    save_iou_dice(cm)\n",
    "    save_patch_iou(all_t, all_p, test_p)\n",
    "    save_area_scatter(all_t, all_p, test_p)\n",
    "    save_roc(all_t, all_prob)\n",
    "    save_overall_metrics_from_cm(cm)\n",
    "    save_metrics_per_class(cm)\n",
    "\n",
    "    print(f\"[DONE] Results are in {RESULTS_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a9ba68f-4d1d-4a09-9501-652ab37a2258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175d4b76-a8d0-4a11-911a-72b1a873665c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e492db-83ba-4463-ac85-9e90339ace5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "892f2c32-585a-4d35-9624-86f71d889a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d9c78-b875-48d8-9659-f9aa7dc0bd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c99cc-0db7-4073-b415-c0aed391105d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frente_invasivo_env",
   "language": "python",
   "name": "frente_invasivo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
